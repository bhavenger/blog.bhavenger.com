+++
date = "2016-04-17T18:39:23+03:00"
description = "Зачем он нужен и что это такое?"
draft = true
tags = ["hadoop", "101"]
title = "Hadoop 101, часть 1"
topics = []

+++
# Hadoop 101
## Какие проблемы решаем?
Данных становится всё больше, сервисы вокруг нас генерируют огромные объемы данных. И данных не просто становится больше - увеличивается скорость их поступления.  
_Например пользователи Facebook-а оставляют около 22 миллиардов лайков и шаров каждый день._  
Для того, чтобы получить от этих сырых данных какую-то ценность - их необходимо как-то обрабатывать.  
И тут мы встречаем две проблемы, связанные с масштабом этих данных:
### Проблемы хранения данных:
#### Скорость дисков - это ограничение.
Объемы дисков растут и цена за гигабайт неуклонно падает. Сейчас можно найти диски с ценою 0.03 бакса за гигабайт.  
К сожалению скорость взаимодействия с диском не поспевает за ростом объема. Сейчас на считывание 3 Тб информации с простого диска вы потратите около 4 часов.  
Несмотря на то, что растущие вычислительные мощности позволяют нам обрабатывать данные гораздо быстрее - доступ(запись и чтение) к ним остается медленным:  
Мы не можем обработать данные до того момента, как их считаем.  
Мы ограничены скоростью одного диска.

#### Объём данных, хранимых на сервере, ограничен ёмкостью сервера.
А что делать, если нам нужно хранить _по-настоящему_ большие данные? До некоторых пределов мы можем апгрейдить наш большой сервер, докупать диски. После - переехать на хранилище данных и апгрейдить уже его. В любом случае мы ограничены ёмкостью хранилища и стоимостью работ по его увеличению.
### Проблема обработки данных:
Объёмы данных для обработки растут. Растут и наборы данных(dataset-ы) для обработки. Со временем вы упретесь в ограничения физического сервера по размеру установленной памяти и количеству ядер процессора.
## Что-же делать?
А что, если уйти от монолитной вычислительной модели с большими и мощными серверами к распределенной модели вычислений?  
Давайте мы будем хранить данные в выделенных хранилищах, а обрабатывать на мощных серверах - и соединим их быстрой сетью?  
Тогда наш процесс обработки данных будет выглядеть следующим образом:  
1. Скопировали данные с хранилища на сервер.  
2. Произвели вычисления.  
3. Скопировали данные с сервера обратно в хранилище.  
Это работает замечательно с небольшими объемами информации, когда больше всего времени занимает шаг 2.  
#### Но что, если данных становится еще больше?
Мы начинаем тратить больше времени не на вычисления, а на процесс копирования из хранилища и обратно.
Ок, добавим еще обработчиков. Ситуация поправится?  
Не совсем:  
- Мы начинаем бороться за пропускную способность сети.  
- Мы начинаем не успевать доставлять данные из хранилищ к обработчикам.  
## Ок, что-же все-таки делать?
Нам нужно решение, которое будет поддерживать простое масштабирование под растущие объемы данных.  
Но нам придется заплатить за это возросшей сложностью системы.  
Мы столкнемся с проблемами
  
* Доступности  
* Консистентности данных  
* Синхронизации событий  
* Ограничений пропускной способности  
* Частичных отказов инфраструктуры  
* Каскадных сбоев в инфраструктуре  

Эти проблемы могут оказаться более сложными, нежели изначальные проблемы, которые мы пытались решить.
### Итак, какие-же требования у нас появились к этой системе?
#### Обработка сбоев: 
Сбои неминуемы. Мы должны уметь справляться с ними.  
Идеальное решение должно обладать следующими свойствами:

* Автоматизированное - Работа должна быть выполнена без ручного вмешательства.  
* Прозрачное - Работы, назначенные на сбойные компоненты, должны подхватываться рабочими компонентами.  
* Изящное - Сбой компоненты должен приводить только к пропорциональной потере производительности системы.  
* Восстанавливаемое - Производительность системы должна восстанавливаться, когда сбойная компонента заменена.  
* Согласованное - Сбои не должны приводить к испорченным или неправильным результатам.

#### Линейная горизонтальная масштабируемость:
* Добавление новых под должно пропорционально увеличивать производительность системы.  
* Архитектура без разделения ресурсов(Shared Nothing architecture) не должна приводить к проблемам.
* Возможность расширения кластера за разумную стоимость.

#### Запускаемые задачи взаимно изолированны:
* Результаты выполнения задач не должны зависеть от задач, которые выполняются параллельно.
* Хотя производительность может быть затронута другими задачами

#### Простая программная модель:
* Система должна поддерживать широко используемые языки программирования.
* API должен быть простым для освоения.

## Hadoop отвечает этим требованиям.
Продолжение во второй части.

