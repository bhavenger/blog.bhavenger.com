+++
date = "2016-06-05T12:01:47+03:00"
description = "Зачем он нужен?"
draft = false
tags = ["hadoop", "101"]
title = "Hadoop 101, часть 1"
topics = []

+++

## Какие проблемы решаем?
Данных становится всё больше, сервисы вокруг нас генерируют огромные объемы данных. И данных не просто становится больше - увеличивается скорость их поступления.  
_Например пользователи Facebook-а делают около 22 миллиардов лайков и расшариваний контента каждый день._  
Для того, чтобы получить от этих сырых данных какую-то ценность - их необходимо как-то обрабатывать.  
И тут мы встречаем проблемы, связанные с масштабом этих данных:
### Хранение большого объема данных:
**Скорость дисков - это ограничение.**  
Объемы дисков растут и цена за гигабайт неуклонно падает. Сейчас можно найти диски с ценою 0.03 бакса за гигабайт. Несмотря на то, что растущие вычислительные мощности позволяют нам обрабатывать данные гораздо быстрее - доступ(запись и чтение) к ним остается медленным - cейчас на считывание 3 Тб информации с простого диска вы потратите около 4 часов. И вы не cможете обработать данные до того момента, как они считаны.  

**Объём данных, хранимых на сервере, ограничен ёмкостью сервера.**  
А что делать, если нам нужно хранить _по-настоящему_ большие данные? До некоторых пределов мы можем апгрейдить наш большой сервер, докупать диски. После - переехать на хранилище данных и апгрейдить уже его. В любом случае мы ограничены ёмкостью хранилища и стоимостью работ по его увеличению.
### Проблема обработки данных:
Объёмы данных для обработки растут. Растут и наборы данных(dataset-ы) для обработки. Со временем вы упретесь в ограничения физического сервера по размеру установленной памяти и количеству ядер процессора.
## Что-же делать?
А что, если уйти от монолитной вычислительной модели с большими и мощными серверами к распределенной модели вычислений?  
Давайте мы будем хранить данные в выделенных хранилищах, а обрабатывать на мощных серверах - и соединим их быстрой сетью?  
Тогда наш процесс обработки данных будет выглядеть следующим образом:  
1. Скопировали данные с хранилища на сервер.  
2. Произвели вычисления.  
3. Скопировали данные с сервера обратно в хранилище.  
Это работает замечательно с небольшими объемами информации, когда больше всего времени занимает шаг 2.  
#### Но что, если данных становится еще больше?
Мы начинаем тратить больше времени не на вычисления, а на процесс копирования из хранилища и обратно.
Ок, добавим еще обработчиков. Ситуация поправится?  
Не совсем:  
- Мы начинаем бороться за пропускную способность сети.  
- Мы начинаем не успевать доставлять данные из хранилищ к обработчикам.  
## Ок, что-же все-таки делать?
Нам нужно решение, которое будет поддерживать простое масштабирование под растущие объемы данных.  
Но нам придется заплатить за это возросшей сложностью системы.  
Мы столкнемся с проблемами
  
* Доступности  
* Консистентности данных  
* Синхронизации событий  
* Ограничений пропускной способности  
* Частичных отказов инфраструктуры  
* Каскадных сбоев в инфраструктуре  

Эти проблемы могут оказаться более сложными, нежели изначальные проблемы, которые мы пытались решить.
### Ок, мы готовы справиться с этими сложностями. Какие-же требования у нас появились к этой системе?
**Обработка сбоев:**  
Сбои неминуемы. Мы должны уметь справляться с ними.  
Идеальное решение должно обладать следующими свойствами:  
* Задачи должны быть выполнимы без ручного вмешательства.  
* Задачи при сбоях серверов должны автоматически перезапускаться на работающих серверах.  
* Сбой сервера\диска должен приводить только к пропорциональной потере производительности системы.  
* Производительность системы должна восстанавливаться, когда сбойная компонента заменена.  
* Сбои не должны приводить к испорченным или неправильным результатам.

**Линейная горизонтальная масштабируемость:**  
* Добавление новых под должно пропорционально увеличивать производительность системы.  
* Архитектура без разделения ресурсов(Shared Nothing Architecture) не должна приводить к проблемам.  
* Возможность расширения кластера за разумную стоимость - никаких суперкомпьютеров.

**Запускаемые задачи взаимно изолированны:**  
* Результаты выполнения задач не должны зависеть от задач, которые выполняются параллельно.  
* Но мы допускаем, что производительность может быть затронута другими задачами.

**Простая программная модель:**  
* Система должна поддерживать широко используемые языки программирования.  
* API должен быть простым для освоения.

**Hadoop отвечает этим требованиям.**  
*Продолжение во второй части.*

